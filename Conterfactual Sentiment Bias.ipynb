{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff03d0a-84f4-443f-ab66-5095d2cbcc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "maping = {'AAVE-dataset': 'African American English', 'AAVE-Filler-words-dataset': 'African American English - Filler Words',\n",
    "         'AAVE-hashtags-words-dataset': 'African American English - Hashtags', 'AAVE-emojis-words-dataset': 'African American English - emojis',\n",
    "         'AAVE-misspelling-words-dataset': 'African American English - misspelling', 'AAVE-misplaced-dangling-modifiers-dataset': 'African American English - Modifiers',\n",
    "         'original_dataset':'Original'}\n",
    "\n",
    "def get_log_prob_datasets(model):\n",
    "    directory_path = f\"./original_{model}/log_prob/\"\n",
    "\n",
    "    dataset_list = []\n",
    "    original = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            if filename in ['wasserstein_distance.csv', 'mean_log_prob.csv']:\n",
    "                continue\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            dataset = pd.read_csv(file_path)\n",
    "            filename = filename.split('.')[0]\n",
    "            if filename == 'original_dataset':\n",
    "                original=dataset\n",
    "                continue\n",
    "            dataset_list.append((dataset, filename))\n",
    "            \n",
    "    return dataset_list, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc33239-6236-4699-9972-8154f4ac5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_datasets, llama_original_dataset = get_log_prob_datasets('llama2')\n",
    "mistral_datasets, mistral_original_dataset  = get_log_prob_datasets('mistral')\n",
    "gemma_datasets, gemma_original_dataset = get_log_prob_datasets('gemma')\n",
    "datasets = [(llama_datasets,llama_original_dataset, 'llama2'), (mistral_datasets,mistral_original_dataset, 'mistral'), (gemma_datasets,gemma_original_dataset, 'gemma')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e10323-bd87-4552-8395-88184b7596bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Log Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hope you do, because otherwise your wife mig...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-11.464495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I constantly worry about their fight against n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-8.739827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel I've had more unhappy years than happy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-3.669981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm feeling I'm caring, I'm healing, I'm shari...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-6.620073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just feel like if I can make it through this...</td>\n",
       "      <td>positive</td>\n",
       "      <td>-6.888464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment   Log Prob\n",
       "0  I hope you do, because otherwise your wife mig...  negative -11.464495\n",
       "1  I constantly worry about their fight against n...  positive  -8.739827\n",
       "2  i feel I've had more unhappy years than happy ...  negative  -3.669981\n",
       "3  I'm feeling I'm caring, I'm healing, I'm shari...  positive  -6.620073\n",
       "4  I just feel like if I can make it through this...  positive  -6.888464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_original_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f940fc9-5a6c-4243-88fb-b197c9b68a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col = mistral_original_dataset['Log Prob'].copy()\n",
    "col = col.map(lambda x: np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c5a54c-ae2b-426d-9a37-875cc7648cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4156501867683275"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = mistral_original_dataset['Log Prob'].map(lambda x: np.exp(x)).to_numpy()\n",
    "abc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09375dc-51e8-4f5c-bfd6-015fa16b57cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.84484887, -10.12582016,  -1.83078396, ...,  -3.75684142,\n",
       "        -2.35400224,  -2.0245266 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_original_dataset['Log Prob'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b889587-d693-46aa-a125-d97a2fa55511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8802225177266423"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_original_dataset['Log Prob'].to_numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb50eb2-8117-455f-a4c9-b5854b3d1faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_datasets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0c166e1-5014-439c-b1d3-0a23c076b656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Model: llama2\n",
      "AAE Dataset: Filler Words\n",
      "wasserstein_distance: 0.053735498273001114\n",
      "=======================\n",
      "Model: llama2\n",
      "AAE Dataset: Emojis\n",
      "wasserstein_distance: 0.01872039747270739\n",
      "=======================\n",
      "Model: llama2\n",
      "AAE Dataset: Misspelling\n",
      "wasserstein_distance: 0.009779570108034331\n",
      "=======================\n",
      "Model: llama2\n",
      "AAE Dataset: Modifiers\n",
      "wasserstein_distance: 0.027426618807157847\n",
      "=======================\n",
      "Model: llama2\n",
      "AAE Dataset: Hashtags\n",
      "wasserstein_distance: 0.015675713437384716\n",
      "=======================\n",
      "Model: mistral\n",
      "AAE Dataset: Emojis\n",
      "wasserstein_distance: 0.019853137461808258\n",
      "=======================\n",
      "Model: mistral\n",
      "AAE Dataset: Filler Words\n",
      "wasserstein_distance: 0.05552762460384117\n",
      "=======================\n",
      "Model: mistral\n",
      "AAE Dataset: Hashtags\n",
      "wasserstein_distance: 0.01196808550011901\n",
      "=======================\n",
      "Model: mistral\n",
      "AAE Dataset: Modifiers\n",
      "wasserstein_distance: 0.03311175348869522\n",
      "=======================\n",
      "Model: mistral\n",
      "AAE Dataset: Misspelling\n",
      "wasserstein_distance: 0.011776698069393505\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: Filler Words\n",
      "wasserstein_distance: 0.005741481874234587\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: Emojis\n",
      "wasserstein_distance: 0.10380428763379722\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: Misspelling\n",
      "wasserstein_distance: 0.0028127200836942064\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: Modifiers\n",
      "wasserstein_distance: 0.005151580107660477\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: Hashtags\n",
      "wasserstein_distance: 0.0058939484360372475\n"
     ]
    }
   ],
   "source": [
    "for model_dataset, model_original, model_name in datasets:\n",
    "    mean_log_prob = pd.DataFrame({'Type':[], 'Mean Log Prob': []})\n",
    "    mean_log_prob = pd.concat([mean_log_prob, pd.DataFrame([{'Type': 'Original','Mean Log Prob': np.mean(model_original['Log Prob'].to_numpy())}])])\n",
    "    wasserstein = pd.DataFrame({'Type':[],'Wasserstein Distance Vs Standard English': []})\n",
    "    org_prob = model_original['Log Prob'].map(lambda x: np.exp(x)).to_numpy()\n",
    "    for aae_dataset, aae_dataset_name in model_dataset:\n",
    "        aae_prob = aae_dataset['Log Prob'].map(lambda x: np.exp(x)).to_numpy()\n",
    "        distance = wasserstein_distance(org_prob,aae_prob)\n",
    "        new_row = {'Type': aae_dataset_name, 'Wasserstein Distance Vs Standard English': distance}\n",
    "        wasserstein = pd.concat([wasserstein, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        mean_log_prob = pd.concat([mean_log_prob, pd.DataFrame([{'Type': aae_dataset_name,'Mean Log Prob': np.mean(aae_dataset['Log Prob'].to_numpy())}])])\n",
    "        print(\"=======================\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"AAE Dataset: {aae_dataset_name}\")\n",
    "        print(f\"wasserstein_distance: {distance}\")\n",
    "    mean_log_prob.to_csv(f\"./original_{model_name}/log_prob/mean_log_prob.csv\", index=False)\n",
    "    wasserstein.to_csv(f\"./original_{model_name}/log_prob/wasserstein_distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112a79a0-ebd3-49c2-8b11-93dc597be5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemma_datasets, gemma_original_dataset = get_log_prob_datasets('gemma')\n",
    "gemma_mean_log = pd.read_csv(f\"./gemma/log_prob/mean_log_prob.csv\")\n",
    "gemma_cfsb = pd.read_csv(f\"./gemma/log_prob/wasserstein_distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac205e82-c548-4dca-9088-a94ee14ce2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: AAVE-dataset\n",
      "wasserstein_distance: 0.004465424608789378\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: AAVE-Filler-words-dataset\n",
      "wasserstein_distance: 0.007281352111851155\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: AAVE-hashtags-words-dataset\n",
      "wasserstein_distance: 0.0035747622821106417\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: AAVE-emojis-words-dataset\n",
      "wasserstein_distance: 0.047846125327148124\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: AAVE-misspelling-words-dataset\n",
      "wasserstein_distance: 0.005231387241108779\n",
      "=======================\n",
      "Model: gemma\n",
      "AAE Dataset: AAVE-misplaced-dangling-modifiers-dataset\n",
      "wasserstein_distance: 0.007336076634154521\n"
     ]
    }
   ],
   "source": [
    "mean_log_prob = pd.DataFrame({'Type':[], 'Mean Log Prob': []})\n",
    "mean_log_prob = pd.concat([mean_log_prob, pd.DataFrame([{'Type': 'Original','Mean Log Prob': np.mean(gemma_original_dataset['Log Prob'].to_numpy())}])])\n",
    "wasserstein = pd.DataFrame({'Type':[],'Wasserstein Distance Vs Standard English': []})\n",
    "org_prob = gemma_original_dataset['Log Prob'].map(lambda x: np.exp(x)).to_numpy()\n",
    "for aae_dataset, aae_dataset_name in gemma_datasets:\n",
    "        aae_prob = aae_dataset['Log Prob'].map(lambda x: np.exp(x)).to_numpy()\n",
    "        distance = wasserstein_distance(org_prob,aae_prob)\n",
    "        new_row = {'Type': maping[aae_dataset_name], 'Wasserstein Distance Vs Standard English': distance}\n",
    "        wasserstein = pd.concat([wasserstein, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        mean_log_prob = pd.concat([mean_log_prob, pd.DataFrame([{'Type': maping[aae_dataset_name],'Mean Log Prob': np.mean(aae_dataset['Log Prob'].to_numpy())}])])\n",
    "        print(\"=======================\")\n",
    "        print(f\"Model: gemma\")\n",
    "        print(f\"AAE Dataset: {aae_dataset_name}\")\n",
    "        print(f\"wasserstein_distance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99a76b7-6505-427d-990d-340975596bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_log_prob.to_csv(f\"./gemma/log_prob/mean_log_prob.csv\", index=False)\n",
    "wasserstein.to_csv(f\"./gemma/log_prob/wasserstein_distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f26c97-9c33-4fee-8dff-9508c518b27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augment",
   "language": "python",
   "name": "augmentation-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
